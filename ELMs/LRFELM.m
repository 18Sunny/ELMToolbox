% LRFELM - Local Receptive Field Extreme Learning Machine
%   Train and Predict a SLFN based on Local Receptive Field Extreme Learning Machine
%
%   This code was implemented based on the following paper:
%
%   [1] G. Bin Huang, Z. Bai, L. L. C. Kasun, and C. M. Vong, 
%       “Local receptive fields based extreme learning machine,” 
%       IEEE Comput. Intell. Mag., vol. 10, no. 2, pp. 18–29, 2015.
%
%   Attributes:
%       Attributes between *.* must be informed.
%       LRFELM objects must be created using name-value pair arguments (see the Usage Example).
%
%                    *imageSize*:   Size of the images that will be used.
%                Accepted Values:   Any 2 (or more) dimensional vector with positive integers.
%
%                     filterSize:   Size of the convolutional filter. (Default = [3,3])
%                Accepted Values:   Any 2 (or more) dimensional vector with positive integers.
%
%                numberOfFilters:   Number of convolutional filters to be used. (Default = 3)
%                Accepted Values:   Any positive integer.
%
%                    sumChannels:   Boolean value indicating if channels (e.g. RGB) are summed or concatenated
%                                   to generate the image "hidden layer output".
%                Accepted Values:   true or false. (Default = true)
%
%                       poolSize:   Size of the "pooling" window. See [1]. (Default = [3,3])
%                Accepted Values:   Any 2 dimensional vector with positive integers.
%
%        regularizationParameter:   Regularization Parameter (defaut = 1000)
%                Accepted Values:   Any positive real number.
%
%                           seed:   Seed to generate the pseudo-random values.
%                                   This attribute is for reproducible research.
%                Accepted Values:   RandStream object or a integer seed for RandStream.
%
%       Attributes generated by the code:
%
%                    inputWeight:   4-D Tensor which stores the random filter weights.
%                                   The fourth dimension corresponds to each filter.
%                                   And the third to each channel.
%
%                   outputWeight:   Weight matrix that connects the hidden
%                                   layer to the output layer
%
%   Methods:
%
%       obj = LRFELM(varargin):     Creates RELM objects. varargin should be in
%                                   pairs. Look attributes
%
%       obj = obj.train(X,Y):       Method for training. X is the input of size N x n,
%                                   where N is (# of samples) and n is the (# of features).
%                                   Y is the output of size N x m, where m is (# of multiple outputs)
%
%       Yhat = obj.predict(X):      Predicts the output for X.
%
%   Usage Example:
%
%       % Generate a random image dataset with 10000 samples, one channel and 28 by 28 pixels;
%       X    = rand(28,28,1,10000);
%       % Generate a random target vector with 3 classes;
%       Y    = rand(10000,3);
%       
%       lrfelm = LRFELM('imageSize',size(trData));
%       lrfelm = lrfelm.train(trData,trLab);
%       Yhat = lrfelm.predict(X);
%
%   Warning:
%
%   Be careful when using this method if you don't have a lot of RAM memory.
%   It creates a "hidden layer" with approximately H*W*numberOfFilters "neurons", 
%   where H and W are the height and width of the images, respectively. 
%   Using small images, with dimensions such as 28 by 28 grayscale images (like the MNIST dataset), 
%   each "filter" results in approx. 28*28=784 "neurons", so if the number of filters is big,
%   the method will need a lot of memory to find the H matrix and it will take time to train.
%   This number will also be multiplied by "numberOfChannels" if the flag "sumChannels" is set to false.
%   Example: using 28 by 28 images with 1 channel, and 10 3x3 filters, the method will need to 
%   find the inverse of a 6760x6760 matrix
%
%   License:
%
%   Permission to use, copy, or modify this software and its documentation
%   for educational and research purposes only and without fee is here
%   granted, provided that this copyright notice and the original authors'
%   names appear on all copies and supporting documentation. This program
%   shall not be used, rewritten, or adapted as the basis of a commercial
%   software or hardware product without first obtaining permission of the
%   authors. The authors make no representations about the suitability of
%   this software for any purpose. It is provided "as is" without express
%   or implied warranty.
%
%       Federal University of Espirito Santo (UFES), Brazil
%       Computers and Neural Systems Lab. (LabCISNE)
%       Authors:    B. L. S. Silva, F. K. Inaba, D. L. Cosmo
%       email:      labcisne@gmail.com
%       website:    github.com/labcisne/ELMToolbox
%       date:       Feb/2018

classdef LRFELM < Util
    
    properties
        regularizationParameter = 1000
        imageSize
        filterSize = [3,3]
        inputWeight
        outputWeight
        poolSize = [3,3]
        numberOfFilters = 3
        sumChannels = true
    end
    
    methods
        function self = LRFELM(varargin)
            for i = 1:2:nargin
                self.(varargin{i}) = varargin{i+1};
            end
            if isempty(self.imageSize)
                throw(MException('LRFELM:emptyImageSize','Image dimension not specified'));
            end
            
            if (numel(self.filterSize) ~= 3)
                self.filterSize = [self.filterSize, self.imageSize(3)];
            elseif (self.filterSize(3) ~= self.imageSize(3))
                throw(MException('LRFELM:wrongFilterDimension','Number of channels of filter and input images should be equal!'));
            end
            
            self.seed = self.parseSeed();
            
            self.imageSize = self.imageSize(1:3);
            A = -1+2*rand(prod(self.filterSize),self.numberOfFilters);
            
            % Orthogonalization using SVD
            % https://github.com/antsfamily/ELM-LRF/blob/master/elmlrfsetup.m
            
            if self.filterSize(1)*self.filterSize(2) < self.numberOfFilters   % r^2 < K
                A = orth(A)';
            else
                A = orth(A);
            end
            
            self.inputWeight = zeros(self.filterSize(1),self.filterSize(2),self.imageSize(3),self.numberOfFilters);
            for j = 1:self.numberOfFilters
                self.inputWeight(:,:,:,j) = reshape(A(:,j), self.filterSize(1), self.filterSize(2),self.imageSize(3));% a is the weight with kernelsize r*r
            end
        end
        
        function self = train(self,X,Y)
            auxTime = toc;
            aux = size(X);
            if ~isequal(self.imageSize, aux(1:3))
                throw(MException('LRFELM:wrongImageDimension','Size of training data is different from the specified in the constructor!'));
            end
            
            H = self.generateHiddenOutput(X);            
            
            if size(H,1) >= size(H,2)
                self.outputWeight = pinv(H'*H + eye(size(H,2))/self.regularizationParameter)*H'*Y;
            else
                self.outputWeight = H'*pinv(eye(size(H,1))/self.regularizationParameter + H*H')*Y;
            end
            self.trainTime = toc - auxTime;
        end
        
        function H = generateHiddenOutput(self,X)
            if self.sumChannels
                H = zeros(self.numberOfFilters,(self.imageSize(1) - self.filterSize(1) + 1)*(self.imageSize(2) - self.filterSize(2) + 1),size(X,4));
                for j=1:self.numberOfFilters
                    C = zeros((self.imageSize(1) - self.filterSize(1) + 1),(self.imageSize(2) - self.filterSize(2) + 1),1,size(X,4));
                    for i=1:size(X,3)
                        C = C + convn(X(:,:,i,:),self.inputWeight(:,:,i,j),'valid');
                    end
                    C = C.^2;
                    H(j,:,:) = reshape(sqrt( convn(C,  ones(self.poolSize),  'same') ), [], size(X,4));
                end
            else
                H = zeros(self.numberOfFilters,self.imageSize(3),(self.imageSize(1) - self.filterSize(1) + 1)*(self.imageSize(2) - self.filterSize(2) + 1),size(X,4));
                for j=1:self.numberOfFilters
                    for i=1:self.imageSize(3)
                        C = convn(X(:,:,i,:),self.inputWeight(:,:,i,j),'valid').^2;
                        %         keyboard;
                        H(j,i,:,:) = reshape(sqrt( convn(C,  ones(self.poolSize),  'same') ), [] , size(X,4));
                    end
                end
            end
            clear C;
            H = reshape(H,[],size(X,4))';
        end
        
        function yh = predict(self,X)
            auxTime = toc;
            aux = size(X);
            if ~isequal(self.imageSize, aux(1:3))
                throw(MException('LRFELM:wrongImageDimension','Size of training data is different from the specified in the constructor!'));
            end
            
            H = self.generateHiddenOutput(X);            
            
            yh = H*self.outputWeight;
            self.lastTestTime = toc - auxTime;
        end
        
    end
end