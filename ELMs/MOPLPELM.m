% PLPELM - Multi Objective Parallel Layer Perceptron Extreme Learning Machine
%   Train and Predict a Multi Objective Parallel Layer Perceptron Extreme Learning Machine
%   * This method is the regularized (ridge) version of PLPELM
%
%   This code was implemented based on the following paper:
%
%   [1] L. D. Tavares, R. R. Saldanha, and D. A. G. Vieira, 
%       “Extreme learning machine with parallel layer perceptrons,” 
%       Neurocomputing, vol. 166, pp. 164–171, 2015.
%
%   [2] L. D. Tavares, “Treinamento Multiobjetivo De Extreme Learning Machines 
%       Utilizando Decomposição em Valores Singulares”. Universidade Federal de 
%       Minas Gerais, Brazil, 2015. (Thesis in Portuguese only)
%
%   Attributes:
%       Attributes between *.* must be informed.
%       MOPLPELM objects must be created using name-value pair arguments (see the Usage Example).
%
%         *numberOfInputNeurons*:   Number of neurons in the input layer.
%                Accepted Values:   Any positive integer.
%
%          numberOfHiddenNeurons:   Number of neurons in each hidden layer
%                Accepted Values:   Any positive integer (defaut = 1000).
%
%        regularizationParameter:   Regularization Parameter (defaut = 1000)
%                Accepted Values:   Any positive real number.
%
%                           seed:   Seed to generate the pseudo-random values.
%                                   This attribute is for reproducible research.
%                Accepted Values:   RandStream object or a integer seed for RandStream.
%
%       Attributes generated by the code:
%
%                        Vmatrix:   Weight matrix that connects the input
%                                   layer to the hidden layer
%
%                        PMatrix:   "Output weights". See [1]
%
%   Methods:
%
%       obj = MOPLPELM(varargin):   Creates RELM objects. varargin should be in
%                                   pairs. Look attributes
%
%           obj = obj.train(X,Y):   Method for training. X is the input of size N x n,
%                                   where N is (# of samples) and n is the (# of features).
%                                   Y is the output of size N x m, where m is (# of multiple outputs)
%
%          Yhat = obj.predict(X):   Predicts the output for X.
%
%   Usage Example:
%
%       [a,b] = iris_dataset;
%       a = a';
%       b = b';
%       [~,b] = max(b,[],2); % MOPLPELM method only supports one dimensional outputs
%       
%       moplpelm = MOPLPELM('numberOfInputNeurons',4);
%       moplpelm = moplpelm.train(a,b);
%       Yhat = moplpelm.predict(a);
%
%   License:
%
%   Permission to use, copy, or modify this software and its documentation
%   for educational and research purposes only and without fee is here
%   granted, provided that this copyright notice and the original authors'
%   names appear on all copies and supporting documentation. This program
%   shall not be used, rewritten, or adapted as the basis of a commercial
%   software or hardware product without first obtaining permission of the
%   authors. The authors make no representations about the suitability of
%   this software for any purpose. It is provided "as is" without express
%   or implied warranty.
%
%       Federal University of Espirito Santo (UFES), Brazil
%       Computers and Neural Systems Lab. (LabCISNE)
%       Authors:    B. L. S. Silva, F. K. Inaba, D. L. Cosmo
%       email:      labcisne@gmail.com
%       website:    github.com/labcisne/ELMToolbox
%       date:       Feb/2018

classdef MOPLPELM < PLPELM
    properties
        regularizationParameter = 1000
    end
    methods
        function self = MOPLPELM(varargin)
            self = self@PLPELM(varargin{:});
        end
        
        function self = train(self,X,Y)
            auxTime = toc;
            if (size(Y,2) ~= 1)
                throw(MException('MOPLPELM:outputSize','MOPLPELM method only supports one dimensional outputs'));
            end
            
            X2 = [X, ones(size(X,1),1)];
            %             V = -1 + 2*rand(size(X2,2),h);
            B = self.activationFunction(X2*self.Vmatrix);
            C = kron(B,ones(1,size(X2,2))).*repmat(X2,[1 self.numberOfHiddenNeurons]);
            
            if (size(C,1) >= size(C,2))
                self.Pmatrix = reshape(pinv(C' * C + eye(size(C,2))/self.regularizationParameter) * C' * Y,size(self.Vmatrix));
            else
                self.Pmatrix = reshape(C' * (pinv(C * C'+ eye(size(C,1))/self.regularizationParameter) * Y),size(self.Vmatrix));
            end

            self.trainTime = toc - auxTime;
        end
    end
end